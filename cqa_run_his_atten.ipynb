{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import itertools\n",
    "from time import time\n",
    "import traceback\n",
    "\n",
    "from cqa_supports import *\n",
    "from cqa_flags import FLAGS\n",
    "from cqa_model import *\n",
    "from cqa_gen_batches import *\n",
    "# from cqa_rl_supports import *\n",
    "from scorer import external_call # quac official evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset : quac\n",
      "ideal_selected_num : 1\n",
      "mtl_input : reduce_mean\n",
      "do_train : True\n",
      "disable_attention : False\n",
      "max_answer_length : 40\n",
      "tpu_zone : None\n",
      "max_query_length : 64\n",
      "pool_size : 3\n",
      "predict_batch_size : 12\n",
      "aux : False\n",
      "null_score_diff_threshold : 0.0\n",
      "f : \n",
      "more_history : 0\n",
      "quac_train_file : /mnt/scratch/chenqu/quac_original/train_v0.2.json\n",
      "bert_hidden : 768\n",
      "max_history_turns : 11\n",
      "train_batch_size : 12\n",
      "do_predict : True\n",
      "only_history_answer : True\n",
      "quac_predict_file : /mnt/scratch/chenqu/quac_original/val_v0.2.json\n",
      "bert_config_file : /mnt/scratch/chenqu/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
      "fine_grained_attention : True\n",
      "init_checkpoint : /mnt/scratch/chenqu/bert/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "vocab_file : /mnt/scratch/chenqu/bert/uncased_L-12_H-768_A-12/vocab.txt\n",
      "history_ngram : 1\n",
      "aux_shared : False\n",
      "glove : /mnt/scratch/chenqu/glove/glove.840B.300d.pkl\n",
      "cache_dir : /mnt/scratch/chenqu/test_ham_cache/\n",
      "aux_lambda : 0.0\n",
      "history_attention_input : reduce_mean\n",
      "embedding_dim : 300\n",
      "master : None\n",
      "iterations_per_loop : 1000\n",
      "num_train_epochs : 2.0\n",
      "gcp_project : None\n",
      "train_steps : 20\n",
      "save_checkpoints_steps : 1000\n",
      "doc_stride : 128\n",
      "MTL_mu : 0.8\n",
      "learning_rate : 3e-05\n",
      "load_small_portion : True\n",
      "better_hae : True\n",
      "use_history_answer_marker : True\n",
      "output_dir : /mnt/scratch/chenqu/bert_out/100000/\n",
      "max_considered_history_turns : 11\n",
      "coqa_predict_file : /mnt/scratch/chenqu/coqa_extractive_gt/coqa-dev-v1.0.json\n",
      "max_question_len_for_matching : 20\n",
      "append_self : False\n",
      "freeze_bert : False\n",
      "num_tpu_cores : 8\n",
      "evaluate_after : 4\n",
      "MTL_lambda : 0.1\n",
      "rl_learning_rate : 0.0001\n",
      "history_selection : previous_j\n",
      "evaluation_steps : 5\n",
      "tpu_name : None\n",
      "use_RL : False\n",
      "MTL : True\n",
      "warmup_proportion : 0.0\n",
      "coqa_train_file : /mnt/scratch/chenqu/coqa_extractive_gt/coqa-train-v1.0.json\n",
      "verbose_logging : False\n",
      "example_batch_size : 4\n",
      "front_padding : False\n",
      "reformulate_question : False\n",
      "max_answer_len_for_matching : 40\n",
      "use_tpu : False\n",
      "n_best_size : 20\n",
      "kernel_size : 3\n",
      "do_lower_case : True\n",
      "history_attention_hidden : False\n",
      "history : 6\n",
      "max_seq_length : 384\n",
      "kernel_count : 16\n",
      "output_dir /mnt/scratch/chenqu/bert_out/100000/\n",
      "WARNING:tensorflow:<<<<<<<<<< load_small_portion is on! >>>>>>>>>>\n",
      "attempting to load train features from cache\n",
      "WARNING:tensorflow:<<<<<<<<<< load_small_portion is on! >>>>>>>>>>\n",
      "attempting to load val features from cache\n",
      "***** Running training *****\n",
      "  Num orig examples = %d 78\n",
      "  Num train_features = %d 446\n",
      "  Batch size = %d 12\n",
      "  Num steps = %d 20\n",
      "training step: 0, total_loss: 5.012562274932861\n",
      "training step: 1, total_loss: 4.875945091247559\n",
      "training step: 2, total_loss: 4.739370346069336\n",
      "training step: 3, total_loss: 4.649376392364502\n",
      "training step: 4, total_loss: 4.8235602378845215\n",
      "training step: 5, total_loss: 4.815892219543457\n",
      "epoch finished! shuffle=False\n",
      "INFO:tensorflow:Writing predictions to: /mnt/scratch/chenqu/bert_out/100000/predictions_5.json\n",
      "INFO:tensorflow:Writing nbest to: /mnt/scratch/chenqu/bert_out/100000/nbest_predictions_5.json\n",
      "evaluation: 5, total_loss: 3.290468692779541, f1: 0.1816558714228953, followup: 0.6808278867102396, yesno: 0.7761437908496732, heq: 0.04084967320261438, dheq: 0.0\n",
      "\n",
      "Model saved in path /mnt/scratch/chenqu/bert_out/100000//model_5.ckpt\n",
      "training step: 6, total_loss: 4.204400062561035\n",
      "training step: 7, total_loss: 4.65286111831665\n",
      "training step: 8, total_loss: 4.289913654327393\n",
      "training step: 9, total_loss: 4.497689247131348\n",
      "training step: 10, total_loss: 4.321810722351074\n",
      "epoch finished! shuffle=False\n",
      "INFO:tensorflow:Writing predictions to: /mnt/scratch/chenqu/bert_out/100000/predictions_10.json\n",
      "INFO:tensorflow:Writing nbest to: /mnt/scratch/chenqu/bert_out/100000/nbest_predictions_10.json\n",
      "evaluation: 10, total_loss: 2.886483669281006, f1: 0.13196761507581808, followup: 0.6808278867102396, yesno: 0.7761437908496732, heq: 0.04084967320261438, dheq: 0.0\n",
      "\n",
      "Model saved in path /mnt/scratch/chenqu/bert_out/100000//model_10.ckpt\n",
      "training step: 11, total_loss: 4.839183807373047\n",
      "training step: 12, total_loss: 3.925586223602295\n",
      "training step: 13, total_loss: 3.48637056350708\n",
      "training step: 14, total_loss: 3.868330240249634\n",
      "training step: 15, total_loss: 4.014838218688965\n",
      "epoch finished! shuffle=False\n",
      "INFO:tensorflow:Writing predictions to: /mnt/scratch/chenqu/bert_out/100000/predictions_15.json\n",
      "INFO:tensorflow:Writing nbest to: /mnt/scratch/chenqu/bert_out/100000/nbest_predictions_15.json\n",
      "evaluation: 15, total_loss: 2.708054304122925, f1: 0.16995009326388974, followup: 0.6808278867102396, yesno: 0.7761437908496732, heq: 0.12254901960784313, dheq: 0.0\n",
      "\n",
      "Model saved in path /mnt/scratch/chenqu/bert_out/100000//model_15.ckpt\n",
      "training step: 16, total_loss: 4.235451698303223\n",
      "training step: 17, total_loss: 3.640453338623047\n",
      "training step: 18, total_loss: 3.8235363960266113\n",
      "training step: 19, total_loss: 3.7541568279266357\n",
      "training step: 20, total_loss: 3.363612174987793\n",
      "epoch finished! shuffle=False\n",
      "INFO:tensorflow:Writing predictions to: /mnt/scratch/chenqu/bert_out/100000/predictions_20.json\n",
      "INFO:tensorflow:Writing nbest to: /mnt/scratch/chenqu/bert_out/100000/nbest_predictions_20.json\n",
      "evaluation: 20, total_loss: 2.679534435272217, f1: 0.14385920022113433, followup: 0.6808278867102396, yesno: 0.7761437908496732, heq: 0.09531590413943355, dheq: 0.0\n",
      "\n",
      "Model saved in path /mnt/scratch/chenqu/bert_out/100000//model_20.ckpt\n"
     ]
    }
   ],
   "source": [
    "for key in FLAGS:\n",
    "    print(key, ':', FLAGS[key].value)\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "\n",
    "if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
    "    raise ValueError(\n",
    "        \"Cannot use sequence length %d because the BERT model \"\n",
    "        \"was only trained up to sequence length %d\" %\n",
    "        (FLAGS.max_seq_length, bert_config.max_position_embeddings))\n",
    "\n",
    "tf.gfile.MakeDirs(FLAGS.output_dir)\n",
    "tf.gfile.MakeDirs(FLAGS.output_dir + '/summaries/train/')\n",
    "tf.gfile.MakeDirs(FLAGS.output_dir + '/summaries/val/')\n",
    "tf.gfile.MakeDirs(FLAGS.output_dir + '/summaries/rl/')\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "print('output_dir', FLAGS.output_dir)\n",
    "\n",
    "if FLAGS.append_self:\n",
    "    FLAGS.cache_dir = FLAGS.cache_dir[:-1] + '_append_self/'\n",
    "    \n",
    "if FLAGS.max_seq_length != 384:\n",
    "    FLAGS.cache_dir = FLAGS.cache_dir[:-1] + '_{}/'.format(FLAGS.max_seq_length)\n",
    "\n",
    "if FLAGS.do_train:\n",
    "    # read in training data, generate training features, and generate training batches\n",
    "    train_examples = None\n",
    "    num_train_steps = None\n",
    "    num_warmup_steps = None\n",
    "    train_file = FLAGS.quac_train_file\n",
    "    train_examples = read_quac_examples(input_file=train_file, is_training=True)\n",
    "        \n",
    "    \n",
    "    # we attempt to read features from cache\n",
    "    features_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/train_features_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "    example_tracker_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/example_tracker_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "    variation_tracker_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/variation_tracker_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "    example_features_nums_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/example_features_nums_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "        \n",
    "    try:\n",
    "        print('attempting to load train features from cache')\n",
    "        with open(features_fname, 'rb') as handle:\n",
    "            train_features = pickle.load(handle)\n",
    "        with open(example_tracker_fname, 'rb') as handle:\n",
    "            example_tracker = pickle.load(handle)\n",
    "        with open(variation_tracker_fname, 'rb') as handle:\n",
    "            variation_tracker = pickle.load(handle)\n",
    "        with open(example_features_nums_fname, 'rb') as handle:\n",
    "            example_features_nums = pickle.load(handle)\n",
    "    except:\n",
    "        print('train feature cache does not exist, generating')\n",
    "        train_features, example_tracker, variation_tracker, example_features_nums = convert_examples_to_variations_and_then_features(\n",
    "                                                            examples=train_examples, tokenizer=tokenizer, \n",
    "                                                            max_seq_length=FLAGS.max_seq_length, doc_stride=FLAGS.doc_stride, \n",
    "                                                            max_query_length=FLAGS.max_query_length, \n",
    "                                                            max_considered_history_turns=FLAGS.max_considered_history_turns, \n",
    "                                                            is_training=True)\n",
    "        with open(features_fname, 'wb') as handle:\n",
    "            pickle.dump(train_features, handle)\n",
    "        with open(example_tracker_fname, 'wb') as handle:\n",
    "            pickle.dump(example_tracker, handle)\n",
    "        with open(variation_tracker_fname, 'wb') as handle:\n",
    "            pickle.dump(variation_tracker, handle)     \n",
    "        with open(example_features_nums_fname, 'wb') as handle:\n",
    "            pickle.dump(example_features_nums, handle) \n",
    "        print('train features generated')\n",
    "                \n",
    "    train_batches = cqa_gen_example_aware_batches_v2(train_features, example_tracker, variation_tracker, example_features_nums, \n",
    "                                                  FLAGS.train_batch_size, FLAGS.num_train_epochs, shuffle=True)\n",
    "    # temp_train_batches = cqa_gen_example_aware_batches_v2(train_features, example_tracker, variation_tracker, example_features_nums, \n",
    "    #                                               24, 1, shuffle=True)\n",
    "    # print('len temp_train_batches', len(list(temp_train_batches)))\n",
    "    \n",
    "    # an estimation of num_train_steps\n",
    "    # num_train_steps = int((math.ceil(len(train_examples) * 1.5 / FLAGS.train_batch_size)) * FLAGS.num_train_epochs)\n",
    "    # we cannot predict the exact training steps because of the \"example-aware\" batching, \n",
    "    # so we run some initial experiments and found out the exact training steps\n",
    "    # num_train_steps = 11438 * FLAGS.num_train_epochs\n",
    "    num_train_steps = FLAGS.train_steps\n",
    "    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n",
    "\n",
    "if FLAGS.do_predict:\n",
    "    # read in validation data, generate val features\n",
    "    val_file = FLAGS.quac_predict_file\n",
    "    val_examples = read_quac_examples(input_file=val_file, is_training=False)\n",
    "\n",
    "    \n",
    "    # we read in the val file in json for the external_call function in the validation step\n",
    "    val_file_json = json.load(open(val_file, 'r'))['data']\n",
    "    \n",
    "    # we attempt to read features from cache\n",
    "    features_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/val_features_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "    example_tracker_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/val_example_tracker_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "    variation_tracker_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/val_variation_tracker_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "    example_features_nums_fname = FLAGS.cache_dir + FLAGS.dataset.lower() + \\\n",
    "                                   '/val_example_features_nums_{}_{}.pkl'.format(FLAGS.load_small_portion, FLAGS.max_considered_history_turns)\n",
    "        \n",
    "    try:\n",
    "        print('attempting to load val features from cache')\n",
    "        with open(features_fname, 'rb') as handle:\n",
    "            val_features = pickle.load(handle)\n",
    "        with open(example_tracker_fname, 'rb') as handle:\n",
    "            val_example_tracker = pickle.load(handle)\n",
    "        with open(variation_tracker_fname, 'rb') as handle:\n",
    "            val_variation_tracker = pickle.load(handle)\n",
    "        with open(example_features_nums_fname, 'rb') as handle:\n",
    "            val_example_features_nums = pickle.load(handle)\n",
    "    except:\n",
    "        print('val feature cache does not exist, generating')\n",
    "        val_features, val_example_tracker, val_variation_tracker, val_example_features_nums = \\\n",
    "                                                        convert_examples_to_variations_and_then_features(\n",
    "                                                        examples=val_examples, tokenizer=tokenizer, \n",
    "                                                        max_seq_length=FLAGS.max_seq_length, doc_stride=FLAGS.doc_stride, \n",
    "                                                        max_query_length=FLAGS.max_query_length, \n",
    "                                                        max_considered_history_turns=FLAGS.max_considered_history_turns, \n",
    "                                                        is_training=False)\n",
    "        with open(features_fname, 'wb') as handle:\n",
    "            pickle.dump(val_features, handle)\n",
    "        with open(example_tracker_fname, 'wb') as handle:\n",
    "            pickle.dump(val_example_tracker, handle)\n",
    "        with open(variation_tracker_fname, 'wb') as handle:\n",
    "            pickle.dump(val_variation_tracker, handle)  \n",
    "        with open(example_features_nums_fname, 'wb') as handle:\n",
    "            pickle.dump(val_example_features_nums, handle)\n",
    "        print('val features generated')\n",
    "    \n",
    "     \n",
    "    num_val_examples = len(val_examples)\n",
    "    \n",
    "\n",
    "# tf Graph input\n",
    "unique_ids = tf.placeholder(tf.int32, shape=[None], name='unique_ids')\n",
    "input_ids = tf.placeholder(tf.int32, shape=[None, FLAGS.max_seq_length], name='input_ids')\n",
    "input_mask = tf.placeholder(tf.int32, shape=[None, FLAGS.max_seq_length], name='input_mask')\n",
    "segment_ids = tf.placeholder(tf.int32, shape=[None, FLAGS.max_seq_length], name='segment_ids')\n",
    "start_positions = tf.placeholder(tf.int32, shape=[None], name='start_positions')\n",
    "end_positions = tf.placeholder(tf.int32, shape=[None], name='end_positions')\n",
    "history_answer_marker = tf.placeholder(tf.int32, shape=[None, FLAGS.max_seq_length], name='history_answer_marker')\n",
    "training = tf.placeholder(tf.bool, name='training')\n",
    "get_segment_rep = tf.placeholder(tf.bool, name='get_segment_rep')\n",
    "yesno_labels = tf.placeholder(tf.int32, shape=[None], name='yesno_labels')\n",
    "followup_labels = tf.placeholder(tf.int32, shape=[None], name='followup_labels')\n",
    "\n",
    "# a unique combo of (e_tracker, f_tracker) is called a slice\n",
    "slice_mask = tf.placeholder(tf.int32, shape=[FLAGS.train_batch_size, ], name='slice_mask') \n",
    "slice_num = tf.placeholder(tf.int32, shape=None, name='slice_num') \n",
    "\n",
    "# for auxiliary loss\n",
    "aux_start_positions = tf.placeholder(tf.int32, shape=[None], name='aux_start_positions')\n",
    "aux_end_positions = tf.placeholder(tf.int32, shape=[None], name='aux_end_positions')\n",
    "\n",
    "bert_representation, cls_representation = bert_rep(\n",
    "        bert_config=bert_config,\n",
    "        is_training=training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        history_answer_marker=history_answer_marker,\n",
    "        use_one_hot_embeddings=False\n",
    "        )\n",
    "\n",
    "reduce_mean_representation = tf.reduce_mean(bert_representation, axis=1)\n",
    "reduce_max_representation = tf.reduce_max(bert_representation, axis=1) \n",
    "\n",
    "if FLAGS.history_attention_input == 'CLS':\n",
    "    history_attention_input = cls_representation    \n",
    "elif FLAGS.history_attention_input == 'reduce_mean':\n",
    "    history_attention_input = reduce_mean_representation\n",
    "elif FLAGS.history_attention_input == 'reduce_max':\n",
    "    history_attention_input = reduce_max_representation\n",
    "else:\n",
    "    print('FLAGS.history_attention_input not specified')\n",
    "    \n",
    "if FLAGS.mtl_input == 'CLS':\n",
    "    mtl_input = cls_representation    \n",
    "elif FLAGS.mtl_input == 'reduce_mean':\n",
    "    mtl_input = reduce_mean_representation\n",
    "elif FLAGS.mtl_input == 'reduce_max':\n",
    "    mtl_input = reduce_max_representation\n",
    "else:\n",
    "    print('FLAGS.mtl_input not specified')\n",
    "    \n",
    "\n",
    "if FLAGS.aux_shared:\n",
    "    # if the aux prediction layer is shared with the main convqa model:\n",
    "    (aux_start_logits, aux_end_logits) = cqa_model(bert_representation)\n",
    "else:\n",
    "    # if they are not shared\n",
    "    (aux_start_logits, aux_end_logits) = aux_cqa_model(bert_representation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if FLAGS.disable_attention:\n",
    "    new_bert_representation, new_mtl_input, attention_weights = disable_history_attention_net(bert_representation, \n",
    "                                                                                     history_attention_input, mtl_input, \n",
    "                                                                                     slice_mask,\n",
    "                                                                                     slice_num)\n",
    "\n",
    "else:\n",
    "    if FLAGS.fine_grained_attention:\n",
    "        new_bert_representation, new_mtl_input, attention_weights = fine_grained_history_attention_net(bert_representation, \n",
    "                                                                                         mtl_input,\n",
    "                                                                                         slice_mask,\n",
    "                                                                                         slice_num)\n",
    "\n",
    "    else:\n",
    "        new_bert_representation, new_mtl_input, attention_weights = history_attention_net(bert_representation, \n",
    "                                                                                         history_attention_input, mtl_input,\n",
    "                                                                                         slice_mask,\n",
    "                                                                                         slice_num)\n",
    "\n",
    "(start_logits, end_logits) = cqa_model(new_bert_representation)\n",
    "yesno_logits = yesno_model(new_mtl_input)\n",
    "followup_logits = followup_model(new_mtl_input)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "# print(tvars)\n",
    "\n",
    "initialized_variable_names = {}\n",
    "if FLAGS.init_checkpoint:\n",
    "    (assignment_map, initialized_variable_names) = modeling.get_assigment_map_from_checkpoint(tvars, FLAGS.init_checkpoint)\n",
    "    tf.train.init_from_checkpoint(FLAGS.init_checkpoint, assignment_map)\n",
    "# print('tvars',tvars)\n",
    "# print('initialized_variable_names',initialized_variable_names)\n",
    "\n",
    "# compute loss\n",
    "seq_length = modeling.get_shape_list(input_ids)[1]\n",
    "def compute_loss(logits, positions):\n",
    "    one_hot_positions = tf.one_hot(\n",
    "        positions, depth=seq_length, dtype=tf.float32)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "    loss = -tf.reduce_mean(tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\n",
    "    return loss\n",
    "\n",
    "# get the max prob for the predicted start/end position\n",
    "start_probs = tf.nn.softmax(start_logits, axis=-1)\n",
    "start_prob = tf.reduce_max(start_probs, axis=-1)\n",
    "end_probs = tf.nn.softmax(end_logits, axis=-1)\n",
    "end_prob = tf.reduce_max(end_probs, axis=-1)\n",
    "\n",
    "start_loss = compute_loss(start_logits, start_positions)\n",
    "end_loss = compute_loss(end_logits, end_positions)\n",
    "\n",
    "yesno_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=yesno_logits, labels=yesno_labels))\n",
    "followup_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=followup_logits, labels=followup_labels))\n",
    "\n",
    "if FLAGS.MTL:\n",
    "    cqa_loss = (start_loss + end_loss) / 2.0\n",
    "    if FLAGS.MTL_lambda < 1:\n",
    "        total_loss = FLAGS.MTL_mu * cqa_loss + \\\n",
    "                     FLAGS.MTL_lambda * yesno_loss + \\\n",
    "                     FLAGS.MTL_lambda * followup_loss\n",
    "    else:\n",
    "        total_loss = cqa_loss + yesno_loss + followup_loss\n",
    "    tf.summary.scalar('cqa_loss', cqa_loss)\n",
    "    tf.summary.scalar('yesno_loss', yesno_loss)\n",
    "    tf.summary.scalar('followup_loss', followup_loss)\n",
    "else:\n",
    "    total_loss = (start_loss + end_loss) / 2.0\n",
    "\n",
    "\n",
    "# if FLAGS.aux:\n",
    "#     aux_start_probs = tf.nn.softmax(aux_start_logits, axis=-1)\n",
    "#     aux_start_prob = tf.reduce_max(aux_start_probs, axis=-1)\n",
    "#     aux_end_probs = tf.nn.softmax(aux_end_logits, axis=-1)\n",
    "#     aux_end_prob = tf.reduce_max(aux_end_probs, axis=-1)\n",
    "#     aux_start_loss = compute_loss(aux_start_logits, aux_start_positions)\n",
    "#     aux_end_loss = compute_loss(aux_end_logits, aux_end_positions)\n",
    "    \n",
    "#     aux_loss = (aux_start_loss + aux_end_loss) / 2.0\n",
    "#     cqa_loss = (start_loss + end_loss) / 2.0\n",
    "#     total_loss = (1 - FLAGS.aux_lambda) * cqa_loss + FLAGS.aux_lambda * aux_loss\n",
    "    \n",
    "#     tf.summary.scalar('cqa_loss', cqa_loss)\n",
    "#     tf.summary.scalar('aux_loss', aux_loss)\n",
    "\n",
    "# else:\n",
    "#     total_loss = (start_loss + end_loss) / 2.0\n",
    "\n",
    "\n",
    "tf.summary.scalar('total_loss', total_loss)\n",
    "\n",
    "if FLAGS.do_train:\n",
    "    train_op = optimization.create_optimizer(total_loss, FLAGS.learning_rate, num_train_steps, num_warmup_steps, False)\n",
    "\n",
    "    print(\"***** Running training *****\")\n",
    "    print(\"  Num orig examples = %d\", len(train_examples))\n",
    "    print(\"  Num train_features = %d\", len(train_features))\n",
    "    print(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
    "    print(\"  Num steps = %d\", num_train_steps)\n",
    "    \n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "RawResult = collections.namedtuple(\"RawResult\", [\"unique_id\", \"start_logits\", \"end_logits\", \"yesno_logits\", \"followup_logits\"])\n",
    "\n",
    "attention_dict = {}\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "tf.get_default_graph().finalize()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    if FLAGS.do_train:\n",
    "        train_summary_writer = tf.summary.FileWriter(FLAGS.output_dir + 'summaries/train', sess.graph)\n",
    "        val_summary_writer = tf.summary.FileWriter(FLAGS.output_dir + 'summaries/val')\n",
    "        rl_summary_writer = tf.summary.FileWriter(FLAGS.output_dir + 'summaries/rl')\n",
    "        \n",
    "        f1_list = []\n",
    "        heq_list = []\n",
    "        dheq_list = []\n",
    "        yesno_list, followup_list = [], []\n",
    "        \n",
    "        # Training cycle\n",
    "        for step, batch in enumerate(train_batches):\n",
    "            if step > num_train_steps:\n",
    "                # this means the learning rate has been decayed to 0\n",
    "                break\n",
    "            \n",
    "            # time1 = time()\n",
    "            batch_features, batch_slice_mask, batch_slice_num, output_features = batch                      \n",
    "\n",
    "            fd = convert_features_to_feed_dict(batch_features) # feed_dict\n",
    "            fd_output = convert_features_to_feed_dict(output_features)\n",
    "            \n",
    "            if FLAGS.better_hae:\n",
    "                turn_features = get_turn_features(fd['metadata'])\n",
    "                fd['history_answer_marker'] = fix_history_answer_marker_for_bhae(fd['history_answer_marker'], turn_features)\n",
    "            \n",
    "            if FLAGS.history_ngram != 1:\n",
    "                batch_slice_mask, group_batch_features = group_histories(batch_features, fd['history_answer_marker'], \n",
    "                                                                                  batch_slice_mask, batch_slice_num)\n",
    "                fd = convert_features_to_feed_dict(group_batch_features)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                _, train_summary, total_loss_res = sess.run([train_op, merged_summary_op, total_loss], \n",
    "                                                feed_dict={unique_ids: fd['unique_ids'], input_ids: fd['input_ids'], \n",
    "                                                input_mask: fd['input_mask'], segment_ids: fd['segment_ids'], \n",
    "                                                start_positions: fd_output['start_positions'], end_positions: fd_output['end_positions'], \n",
    "                                                history_answer_marker: fd['history_answer_marker'], slice_mask: batch_slice_mask, \n",
    "                                                slice_num: batch_slice_num, \n",
    "                                                aux_start_positions: fd['start_positions'], aux_end_positions: fd['end_positions'],\n",
    "                                                yesno_labels: fd_output['yesno'], followup_labels: fd_output['followup'], training: True})\n",
    "            except Exception as e:\n",
    "                print('training, features length: ', len(batch_features))\n",
    "                print(e)\n",
    "                traceback.print_tb(e.__traceback__)\n",
    "\n",
    "            train_summary_writer.add_summary(train_summary, step)\n",
    "            train_summary_writer.flush()\n",
    "            # print('attention weights', attention_weights_res)\n",
    "            print('training step: {}, total_loss: {}'.format(step, total_loss_res))\n",
    "            # time2 = time()\n",
    "            # print('train step', time2-time1)\n",
    "            \n",
    "            \n",
    "            if (step % 3000 == 0 or \\\n",
    "                (step >= FLAGS.evaluate_after and step % FLAGS.evaluation_steps == 0)) and \\\n",
    "                step != 0:\n",
    "#             if step >= FLAGS.evaluate_after and step % FLAGS.evaluation_steps == 0:\n",
    "                    \n",
    "                val_total_loss = []\n",
    "                all_results = []\n",
    "                all_output_features = []\n",
    "                \n",
    "                val_batches = cqa_gen_example_aware_batches_v2(val_features, val_example_tracker, val_variation_tracker, \n",
    "                                                  val_example_features_nums, FLAGS.predict_batch_size, 1, shuffle=False)\n",
    "                \n",
    "                for val_batch in val_batches:\n",
    "                    # time3 = time()\n",
    "                    batch_results = []\n",
    "                    batch_features, batch_slice_mask, batch_slice_num, output_features = val_batch\n",
    "                        \n",
    "                    try:\n",
    "                        all_output_features.extend(output_features)\n",
    "\n",
    "                        fd = convert_features_to_feed_dict(batch_features) # feed_dict\n",
    "                        fd_output = convert_features_to_feed_dict(output_features)\n",
    "\n",
    "                        if FLAGS.better_hae:\n",
    "                            turn_features = get_turn_features(fd['metadata'])\n",
    "                            fd['history_answer_marker'] = fix_history_answer_marker_for_bhae(fd['history_answer_marker'], turn_features)\n",
    "                            \n",
    "                        if FLAGS.history_ngram != 1:                     \n",
    "                            batch_slice_mask, group_batch_features = group_histories(batch_features, fd['history_answer_marker'], \n",
    "                                                                                  batch_slice_mask, batch_slice_num)\n",
    "                            fd = convert_features_to_feed_dict(group_batch_features)\n",
    "                        \n",
    "                        start_logits_res, end_logits_res, \\\n",
    "                        yesno_logits_res, followup_logits_res, \\\n",
    "                        batch_total_loss, \\\n",
    "                        attention_weights_res = sess.run([start_logits, end_logits, yesno_logits, followup_logits, \n",
    "                                                          total_loss, attention_weights], \n",
    "                                    feed_dict={unique_ids: fd['unique_ids'], input_ids: fd['input_ids'], \n",
    "                                    input_mask: fd['input_mask'], segment_ids: fd['segment_ids'], \n",
    "                                    start_positions: fd_output['start_positions'], end_positions: fd_output['end_positions'], \n",
    "                                    history_answer_marker: fd['history_answer_marker'], slice_mask: batch_slice_mask, \n",
    "                                    slice_num: batch_slice_num,\n",
    "                                    aux_start_positions: fd['start_positions'], aux_end_positions: fd['end_positions'],\n",
    "                                    yesno_labels: fd_output['yesno'], followup_labels: fd_output['followup'], training: False})\n",
    "\n",
    "                        val_total_loss.append(batch_total_loss)\n",
    "                        \n",
    "                        key = (tuple([val_examples[f.example_index].qas_id for f in output_features]), step)\n",
    "                        attention_dict[key] = {'batch_slice_mask': batch_slice_mask, 'attention_weights_res': attention_weights_res,\n",
    "                                              'batch_slice_num': batch_slice_num, 'len_batch_features': len(batch_features),\n",
    "                                              'len_output_features': len(output_features)}\n",
    "\n",
    "                        for each_unique_id, each_start_logits, each_end_logits, each_yesno_logits, each_followup_logits \\\n",
    "                                in zip(fd_output['unique_ids'], start_logits_res, end_logits_res, yesno_logits_res, followup_logits_res):  \n",
    "                            each_unique_id = int(each_unique_id)\n",
    "                            each_start_logits = [float(x) for x in each_start_logits.flat]\n",
    "                            each_end_logits = [float(x) for x in each_end_logits.flat]\n",
    "                            each_yesno_logits = [float(x) for x in each_yesno_logits.flat]\n",
    "                            each_followup_logits = [float(x) for x in each_followup_logits.flat]\n",
    "                            batch_results.append(RawResult(unique_id=each_unique_id, start_logits=each_start_logits, \n",
    "                                                           end_logits=each_end_logits, yesno_logits=each_yesno_logits,\n",
    "                                                          followup_logits=each_followup_logits))\n",
    "\n",
    "                        all_results.extend(batch_results)\n",
    "                    except Exception as e:\n",
    "                        print('batch dropped because too large!')\n",
    "                        print('validating, features length: ', len(batch_features))\n",
    "                        print(e)\n",
    "                        traceback.print_tb(e.__traceback__)\n",
    "                    # time4 = time()\n",
    "                    # print('val step', time4-time3)\n",
    "                output_prediction_file = os.path.join(FLAGS.output_dir, \"predictions_{}.json\".format(step))\n",
    "                output_nbest_file = os.path.join(FLAGS.output_dir, \"nbest_predictions_{}.json\".format(step))\n",
    "                output_null_log_odds_file = os.path.join(FLAGS.output_dir, \"output_null_log_odds_file_{}.json\".format(step))\n",
    "                \n",
    "                # time5 = time()\n",
    "                write_predictions(val_examples, all_output_features, all_results,\n",
    "                                  FLAGS.n_best_size, FLAGS.max_answer_length,\n",
    "                                  FLAGS.do_lower_case, output_prediction_file,\n",
    "                                  output_nbest_file, output_null_log_odds_file)\n",
    "                # time6 = time()\n",
    "                # print('write all val predictions', time6-time5)\n",
    "                val_total_loss_value = np.average(val_total_loss)\n",
    "                                \n",
    "                \n",
    "                # call the official evaluation script\n",
    "                val_summary = tf.Summary() \n",
    "                # time7 = time()\n",
    "                val_eval_res = external_call(val_file_json, output_prediction_file)\n",
    "                # time8 = time()\n",
    "                # print('external call', time8-time7)\n",
    "                val_f1 = val_eval_res['f1']\n",
    "                val_followup = val_eval_res['followup']\n",
    "                val_yesno = val_eval_res['yes/no']\n",
    "                val_heq = val_eval_res['HEQ']\n",
    "                val_dheq = val_eval_res['DHEQ']\n",
    "\n",
    "                heq_list.append(val_heq)\n",
    "                dheq_list.append(val_dheq)\n",
    "                yesno_list.append(val_yesno)\n",
    "                followup_list.append(val_followup)\n",
    "\n",
    "                val_summary.value.add(tag=\"followup\", simple_value=val_followup)\n",
    "                val_summary.value.add(tag=\"val_yesno\", simple_value=val_yesno)\n",
    "                val_summary.value.add(tag=\"val_heq\", simple_value=val_heq)\n",
    "                val_summary.value.add(tag=\"val_dheq\", simple_value=val_dheq)\n",
    "\n",
    "                print('evaluation: {}, total_loss: {}, f1: {}, followup: {}, yesno: {}, heq: {}, dheq: {}\\n'.format(\n",
    "                    step, val_total_loss_value, val_f1, val_followup, val_yesno, val_heq, val_dheq))\n",
    "                with open(FLAGS.output_dir + 'step_result.txt', 'a') as fout:\n",
    "                        fout.write('{},{},{},{},{},{},{}\\n'.format(step, val_f1, val_heq, val_dheq, \n",
    "                                                                   val_yesno, val_followup, FLAGS.output_dir))\n",
    "                \n",
    "                val_summary.value.add(tag=\"total_loss\", simple_value=val_total_loss_value)\n",
    "                val_summary.value.add(tag=\"f1\", simple_value=val_f1)\n",
    "                f1_list.append(val_f1)\n",
    "                val_summary_writer.add_summary(val_summary, step)\n",
    "                val_summary_writer.flush()\n",
    "                \n",
    "                save_path = saver.save(sess, '{}/model_{}.ckpt'.format(FLAGS.output_dir, step))\n",
    "                print('Model saved in path', save_path)\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = max(f1_list)\n",
    "best_f1_idx = f1_list.index(best_f1)\n",
    "best_heq = heq_list[best_f1_idx]\n",
    "best_dheq = dheq_list[best_f1_idx]\n",
    "best_yesno = yesno_list[best_f1_idx]\n",
    "best_followup = followup_list[best_f1_idx]\n",
    "with open(FLAGS.output_dir + 'result.txt', 'w') as fout:\n",
    "    fout.write('{},{},{},{},{},{},{},{},{},{},{}\\n'.format(best_f1, best_heq, best_dheq, best_yesno, best_followup,\n",
    "                                                  FLAGS.MTL_lambda, FLAGS.MTL_mu, FLAGS.MTL, FLAGS.mtl_input,\n",
    "                                                  FLAGS.history_attention_input, FLAGS.output_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
